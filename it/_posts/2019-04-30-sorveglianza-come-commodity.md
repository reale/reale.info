---
title: "Sorveglianza come commodity"
lang: it
ref: sorveglianza-come-commodity
categories: [publications, articles]
tags: [surveillance, society, politics]
featured_image: /assets/images/2019-04-30-sorveglianza-come-commodity.jpg
publication: "Eventual Consistency"
canonical: https://medium.com/reale/sorveglianza-come-commodity-da92cc51d952
---

Combinando lo stream di videocamere liberamente accessibili su Internet, alcune migliaia di foto profilo pubbliche raccolte sui social, ed il servizio di riconoscimento facciale di Amazon (un classico esempio di Machine-Learning-as-a-Service), [i ricercatori del Privacy Project del NYT riescono a ricostruire i movimenti giornalieri di un uomo nella folla](https://www.nytimes.com/interactive/2019/04/16/opinion/facial-recognition-new-york-city.html). Spendendo non più di 100$.

Sorveglianza come commodity.

Foucault, qualcuno se ne ricorderà, in quel testo obbligatorio che è *Surveiller et punir* descrive la formazione di una società "disciplinare" la quale «approda al meccanismo indefinitamente generalizzabile del "panottismo"» (la sorveglianza integrale) in grado di assicurare «una distribuzione infinitesimale dei rapporti di potere».

In altri termini, la normalizzazione della sorveglianza finisce per rendere inutile la sanzione penale, perché i comportamenti devianti verrebbero progressivamente aggrediti dalla consapevolezza di avere, ciascuno di noi, costantemente gli "occhi del potere" addosso.

È, in buona misura, la scelta di Singapore.

Privacy in cambio di sicurezza, insomma. Anzi, più realisticamente, privacy in cambio del diritto che la classe dominante si arroga di garantire il proprio modello di sicurezza, perché (è sempre Foucault a ricordarcelo) un sistema penale è «come un meccanismo per gestire gli illegalismi in modo differenziato e non per sopprimerli tutti».

E noi, da che parte facciamo pendere la bilancia?

Se decidiamo che l'evidenza di colpevolezza, o anche solo il fumus commissi delicti, entrambi espressi dall'algoritmo come distribuzione di probabilità, sono tali al di sopra di una certa soglia; se decidiamo questo, di quali strumenti disponiamo per valutare il procedimento che quello stesso algoritmo avrà seguito, sempre meno deterministico, sempre più opaco e impenetrabile?

Come garantiamo, soprattutto, il rispetto delle garanzie costituzionali? Dei diritti fondamentali?
